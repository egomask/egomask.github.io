<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EgoMask-3DGS">
  <meta name="keywords" content=": Egocentric Video, Dynamic 3D Gaussian Splatting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Egocentric 4D Complex Scene Rendering and Hands Decomposition with Deformable 3D Gaussian Splatting</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          AImove: Human Motion Capture Benchmark
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://www.kaggle.com/datasets/olivasbre/aimove">
            AImove Dataset
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Egocentric 4D Complex Scene Rendering and Hands Decomposition with Deformable 3D Gaussian Splatting</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="http://www.mines-paristech.fr/Services/Annuaire/sichen-su">Sichen SU</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.caor.minesparis.psl.eu/equipe/www.sotirismanitsaris.eu">Sotiris Manitsaris</a><sup>1</sup>,</span> 
            <span class="author-block">
              <a href="http://www.mines-paristech.fr/Services/Annuaire/alina-glushkova">Alina Glushkova</a><sup>1</sup>,</span> 
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Centre for Robotics, Mines Paris, PSL Université</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <figure>
        <img src="./static/pipeline/Egomask.png" alt="EgoMask-3DGS Pipeline" height="100%">
      </figure>
      <h2 class="subtitle has-text-centered">
            EgoMask-3DGS represents dynamic 3D scenes and decomposes human hands from RGB egocentric input.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>

            Egocentric vision is one of the methods for understanding human interaction patterns with the surrounding environment. 
            In this paper, we present EgoMask-3DGS, a novel pipeline designed to represent dynamic 3D scenes and decompose hand movements within 3D dynamic scenes from an egocentric perspective.
            EgoMask-3DGS focuses on the egocentric datasets in the manufacturing industry, which feature complex hand motions and a variety of materials encountered in real-world scenarios. 
            To accurately capture and represent diverse materials—such as transparent, deformable, and solid objects—under different lighting conditions, 
            we employ 3D Gaussian models, depth prior information, and hand prior masks to guide the dynamic scene representation process.
            We validate our pipeline using a custom handicraft dataset that includes  industrial scenes with different materials. 
            Our method effectively represents these varied materials and decomposes hand movements within dynamic scenes. 
            Experimental results highlight the potential of our approach for enhanced 3D dynamic egocentric perception and precise hand decomposition.

          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Dynamic representation</h2>
            <p>
              We showcase our pipeline rendering outcomes. The rendering video, which employs initial camera views, is displayed in the first row. 
              The ground truth video, rendering video, and the static scene and hands scene decomposition results are displayed from left to right. 
              The fixed view results are displayed in the second row. The dynamic scene, static scene, and hands layer are visible from left to right. 
            </p>
      <!-- Re-rendering. -->
        <h3 class="title is-4">Marble Rendering</h3>
        <div class="content has-text-justified">
          <p>
            The marble craft case involves two actions: first, the right hand depicts the engraved lines, while the left hand holds the tool steady on the table; 
            second, carving the marble with the instrument, both hands holding the tool, following the engraved lines while the body rotates to the right in a repetitive motion.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="marble-video-action-1" controls muted preload playsinline width="130%">
            <source src="./static/craft/Marble_video_action_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="marble-video-action-2" controls muted preload playsinline width="130%">
            <source src="./static/craft/Marble_video_action_2.mp4" type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->
        
        <!-- Re-rendering. -->
        <h3 class="title is-4">Galss Rendering</h3>
        <div class="content has-text-justified">
          <p>
            
            Glass craft involves the process of heating glass. 
            The first video shows the process of holding a glass tube in the left hand and turning the tube with the fingers to heat it while the right hand adjusts the heater. 
            The second video shows the process of holding the glass tube in both hands and heating it continuously by changing the position of the glass tube to ensure even heating.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="marble-video-action-1" controls muted preload playsinline width="130%">
            <source src="./static/craft/glass_video_action_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="marble-video-action-2" controls muted preload playsinline width="130%">
            <source src="./static/craft/glass_video_action_2.mp4" type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->

      <!-- Re-rendering. -->
        <h3 class="title is-4">Glove Rendering</h3>
        <div class="content has-text-justified">
          <p>
            Glove craft involves the glove handcraft process, which includes detailed hand-finger motions. T
            he first video shows the process of holding the leather in the left hand and searching for the tool with the right hand, accompanied by a lot of quick, instant motions. 
            The second video shows the leather strip process, where the left hand holds the leather and the right hand holds the tool to split the leather.
          </p>
        </div>
      <div class="content has-text-centered">
          <video id="marble-video-action-1" controls muted preload playsinline width="130%">
            <source src="./static/craft/leather_video_action_1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-centered">
          <video id="marble-video-action-2" controls muted preload playsinline width="130%">
            <source src="./static/craft/leather_video_action_2.mp4" type="video/mp4">
          </video>
        </div>
        <!--/ Re-rendering. -->
      </div>
    </div>
    <!--/ Animation. -->



    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            It borrows the source code of <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            We sincerely thank <a
              href="https://github.com/keunhong">Keunhong Park </a>  for developing and open-sourcing this template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
